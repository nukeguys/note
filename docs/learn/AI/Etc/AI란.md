# AI란?

## 1. 인공지능(AI)의 정의와 철학적 기원

인공지능은 단순히 기술적인 산물이 아니라, '인간의 지능을 기계로 완벽히 모방할 수 있다'는 철학적 가설에서 시작되었습니다.

### 1.1. 인공지능의 철학적 토대

AI의 기원은 "인간의 사고는 일정한 규칙에 따른 계산 과정인가?"라는 질문과 맞닿아 있습니다.

- **Computationalism (계산주의):** 홉스(Hobbes)와 라이프니츠(Leibniz) 같은 철학자들은 "사고는 계산이다"라고 주장했습니다. 즉, 인간의 복잡한 생각도 결국 논리적인 기호의 조합과 연산으로 환원될 수 있다는 믿음이 AI 탄생의 배경이 되었습니다.
- **Turing Test (튜링 테스트):** 앨런 튜링은 "기계가 지능이 있는가?"라는 형이상학적 질문 대신, "기계가 인간과 구별할 수 없을 정도로 대화할 수 있는가?"라는 실용적인 판별법을 제시하며 AI 연구의 구체적인 목표를 설정했습니다.

### 1.2. Symbolic AI (기호주의) vs Connectionism (연결주의)

지능을 구현하는 철학적 방법론에 따라 두 갈래로 나뉩니다.

- **Symbolic AI (기호주의):** 지능을 명시적인 규칙과 논리의 조합으로 봅니다. '인간의 지식은 언어와 기호로 정의될 수 있다'는 전제하에 전문가 시스템(Expert Systems)을 구축하며, 사람이 직접 IF-THEN 식의 규칙을 프로그래밍(Hand-coded rules)합니다.
- **Connectionism (연결주의):** 지능을 뇌의 생물학적 구조, 즉 신경망의 연결에서 기인한다고 봅니다. '지능은 개별 규칙이 아니라 수많은 단순한 유닛들의 상호작용에서 창발(Emergence)한다'는 철학을 바탕으로 하며, 이것이 현대 **Deep Learning**의 근간이 되었습니다.

### 1.3. ANI(Artificial Narrow Intelligence)와 AGI(Artificial General Intelligence)

지능의 범용성에 따라 AI를 분류하는 기준입니다.

- **ANI (약인공지능):** 특정 도메인(바둑, 번역, 이미지 분류 등) 내에서만 지능을 발휘합니다. 현재 우리가 사용하는 모든 AI 시스템이 여기에 해당합니다.
- **AGI (범용인공지능):** 인간처럼 자의식을 가질 수 있고, 처음 접하는 문제도 스스로 학습하여 해결할 수 있는 완전한 지능을 의미합니다. 현대 AI 연구의 최종 지향점입니다.

## 2. Machine Learning(머신러닝)의 핵심 메커니즘

Machine Learning은 명시적인 프로그래밍 없이 데이터로부터 학습하는 알고리즘을 구축하는 기술입니다.

### 2.1. 학습 패러다임의 분류

AI가 지능을 획득하는 방법은 데이터의 성격과 목표에 따라 세 가지로 구분됩니다.

1. **Supervised Learning (지도 학습):** 정답이 표기된 **Label** 데이터셋을 통해 입력값과 결과값 사이의 함수 관계를 학습합니다. (예: Regression, Classification)
2. **Unsupervised Learning (비지도 학습):** Label 없이 데이터의 구조나 분포를 분석하여 스스로 특징을 찾아냅니다. (예: Clustering, Dimensionality Reduction)
3. **Reinforcement Learning (강화 학습):** 에이전트가 환경과 상호작용하며 **Reward**를 최대화하기 위한 정책(Policy)을 학습합니다. 시행착오를 통한 최적화가 핵심입니다.

### 2.2. Loss Function(손실 함수)과 Optimization(최적화)

학습의 본질은 수학적 오차를 줄이는 과정입니다.

- **Loss Function:** AI의 예측값과 실제 정답 사이의 차이를 수치화한 지표입니다.
- **Optimization:** 이 오차를 최소화하기 위해 **Gradient Descent (경사하강법)** 알고리즘을 사용하여 모델의 내부 파라미터를 점진적으로 수정합니다.

## 3. Deep Learning(딥러닝)과 현대적 진화

Deep Learning은 인간의 뇌 신경망을 모방한 **ANN(Artificial Neural Networks)**의 층을 깊게 쌓아(Deep) 복잡한 데이터를 처리합니다.

### 3.1. Backpropagation (역전파 알고리즘)

학습 과정에서 발생한 오차를 출력층에서 입력층 방향으로 거꾸로 전달하며, 각 연결의 **Weights(가중치)** 를 얼마나 수정해야 할지 계산하는 핵심 알고리즘입니다.

### 3.2. Transformer와 Attention Mechanism

현재 생성형 AI 혁명을 이끌고 있는 기술적 정점입니다.

- **Self-Attention:** 입력된 시퀀스(문장 등) 내에서 각 요소들이 서로 어떤 연관성을 갖는지 가중치를 계산합니다. 문맥 속에서 중요한 정보에 '집중(Attention)'하여 이해의 정확도를 획기적으로 높였습니다.
- **Parallel Processing:** 데이터를 순차적으로 처리하던 기존 방식과 달리 전체 데이터를 한꺼번에 병렬로 처리하여, 초거대 규모의 **Foundation Model** 학습을 가능하게 했습니다.

### 💡 개론 요약

인공지능은 **데이터(Data)** 를 연료로, **알고리즘(Algorithm)** 을 엔진으로 하며, **컴퓨팅 파워(Compute)** 라는 가속기를 통해 작동합니다. 결국 AI 개론의 핵심은 "데이터에서 어떻게 유의미한 패턴을 수학적으로 추출하고, 이를 새로운 상황에 적용(Inference)하느냐"에 있습니다.
