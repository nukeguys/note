# API 호출 vs LangChain 구현 비교

## 1. AnythingLLM/Open WebUI API를 쓰는 경우 (현재 단계 추천)

이 도구들은 이미 완성된 **'RAG 서버'** 입니다. 앱은 이 서버에 질문만 던지는 '클라이언트' 역할을 합니다.

- **방식:** 내 앱 ↔ API ↔ AnythingLLM (RAG 처리) ↔ Ollama
- **장점:**
  - **속도:** RAG 로직(청킹, 벡터 검색, 프롬프트 구성)을 직접 짤 필요가 없음.
  - **관리:** 문서 추가/삭제를 AnythingLLM 관리 화면에서 마우스로 할 수 있음.
- **한계:** \* 서비스 로직이 AnythingLLM이 제공하는 API 규격 안에 갇힘.
  - 복잡한 전처리나 특수한 검색 알고리즘을 중간에 끼워 넣기 어려움.

## 2. LangChain으로 직접 백엔드를 짜는 경우 (고도화 단계)

이때는 AnythingLLM을 통하지 않고, 백엔드 코드 내에 RAG 기능을 직접 심는 것입니다.

- **방식:** 내 앱 ↔ 백엔드(LangChain 기반) ↔ Ollama
- **장점:**
  - **자유도:** 검색 결과가 맘에 안 들 때 검색 알고리즘을 1% 단위로 수정 가능.
  - **복합 에이전트:** "DB 조회 + 웹 검색 + 계산기 사용" 등 여러 도구를 복합적으로 쓰는 에이전트 구현이 용이함.
  - **비용/최적화:** 서비스 규모가 커질 때 불필요한 UI 기능을 떼고 RAG 핵심 로직만 가볍게 돌릴 수 있음.

## 3. 실무적인 선택 기준 (Decision Matrix)

| 구분            | AnythingLLM/Open WebUI API 활용      | LangChain 직접 구현                          |
| :-------------- | :----------------------------------- | :------------------------------------------- |
| **추천 상황**   | 빠르게 MVP(최소 기능 제품)를 만들 때 | 독창적인 AI 로직이나 정밀한 제어가 필요할 때 |
| **난이도**      | 낮음 (API 문서 보고 호출만 하면 됨)  | 높음 (RAG의 각 단계를 직접 코딩해야 함)      |
| **데이터 관리** | 제공되는 관리 화면에서 편리하게 관리 | DB 관리 및 인덱싱 로직을 직접 관리           |
