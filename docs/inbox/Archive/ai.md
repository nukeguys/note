LLM
다음 단어(토큰)를 확률적으로 예측하는 모델 (학습 데이터를 기반으로)

토큰
문자나 단어와는 다른 단위, 성능이나 비용, 길이 제한에 사용

Context Window
입력받고 처리할 수 있는 텍스트의 길이 (토큰 단위)

프롬프트 엔지니어링
역할, 목표, 제약조건, 입력, 출력 형식

Temperature
얼마나 창의적 / 안정적으로 만들 것인가
- 0에 가까울 수록 안정적/정확도 중시
- 0.7 보편적, 자연스러움
- 1.0이상 창의적

Top-P
확률 분포를 얼마나 잘라낼지 (얼마나 많은 후보를 기준으로 선택할지)
- 작을 수록 보수적, 클 수록 창의적
보통 기본값으로 두고 Temperature를 조절

프롬프트 설계 패턴
- Chain of Thought: 생각 과정을 설명하도록 요구
- Few-Show Prompting: 예시 + 새로운 입력으로 학습
- Role Prompting: 전문가 캐릭터 부여
- Reflection pattern: 자가 검증
- Deliberate Prompting: 여러 후보 생성 후 선택

프롬프트 평가
(측정 가능)
- 정합성: 요구사항과 일치
- 안정성: 같읕 입력에 같은 결과
- 일반화: 다양한 입력에 동작
- 정확성: 사실 기반
- 효율성: 불필요한 내용 없이 전달

테스트 테이터 (입력 + 이상적인 출력)
프롬프트 반복 실행 후 출력 평가

Tool Calling
LLM과 외부 시스템을 연결