# AI는 어떻게 대화를 기억하는가? (Context & Memory)

## 1. 핵심 원리: 사실 모델은 "까먹는다"

- **반전:** Llama나 GPT 같은 모델 자체는 '상태'가 없습니다(Stateless). 즉, 한 번 답변하고 나면 모든 걸 잊어버립니다.
- **기억의 비밀:** 우리가 질문할 때 **이전 대화 전체 + 내 새로운 질문**을 통째로 묶어서 다시 보내주는 것입니다.
- **비유:** 치매에 걸린 비서에게 매번 "어제 이런 일이 있었고, 방금 이런 말을 했으니, 이제 다음 일을 해줘"라고 처음부터 다시 설명해주는 것과 같습니다.

## 2. API 호출 시 기억을 유지하는 방법 (세션 관리)

### ① AnythingLLM / Open WebUI API 사용 시 (쉬운 방법)

이 도구들은 서버 내부에서 **'세션(Session)'** 이나 **'스레드(Thread) ID'** 를 관리해줍니다.

- **작동 방식:**
  1. 첫 질문 시 서버가 `chat_id` 또는 `session_id`를 줍니다.
  2. 다음 질문을 할 때 이 `ID`를 함께 보냅니다.
  3. 서버는 DB에 저장해둔 이전 대화 기록을 꺼내서 질문 앞에 자동으로 붙여 모델에게 전달합니다.
- **장점:** 앱 개발자가 대화 로그를 직접 관리할 필요가 없습니다.

### ② LangChain으로 직접 구현 시 (정교한 방법)

개발자가 직접 **Memory 객체**를 설정해야 합니다.

- **ConversationBufferMemory:** 이전 대화 전체를 그대로 저장하고 전달.
- **ConversationSummaryMemory:** 대화가 너무 길어지면 요약해서 핵심만 전달 (토큰 절약).
- **Window Memory:** 최근 5개나 10개의 대화만 기억하고 오래된 건 삭제.

## 3. 개인화 서비스 앱에서의 구현 흐름

1. **사용자 앱:** 질문 입력 ("아까 말한 결혼식 때 입을 옷 다시 보여줘")
2. **백엔드(API):**
   - DB에서 해당 유저의 최근 대화 내역(`History`)을 조회.
   - RAG를 통해 관련 문서(`Context`)를 가져옴.
3. **최종 프롬프트 구성:**
   > 시스템 지침: 너는 코디 비서야.
   > 과거 대화: "사용자: 작년 결혼식 때 뭐 입었지?" / "AI: 네이비 수트를 입으셨습니다."
   > 검색된 지식: 네이비 수트 상세 정보...
   > 새로운 질문: "그거 다시 보여줘"
4. **모델 응답:** "네, 작년에 입으셨던 네이비 수트 사진과 정보를 다시 보여드릴게요."

## 4. 주의사항: 컨텍스트 윈도우(Context Window)

- 모델마다 한 번에 읽을 수 있는 양(토큰)이 정해져 있습니다.
- 대화가 무한히 길어지면 어느 순간 모델이 감당을 못 하거나 답변이 느려집니다.
- **해결책:** 맥미니 32GB에서는 컨텍스트가 큰 모델(예: Llama 3.1은 128k까지 지원)을 쓰거나, 중간에 이전 대화를 요약해주는 로직이 필요합니다.
